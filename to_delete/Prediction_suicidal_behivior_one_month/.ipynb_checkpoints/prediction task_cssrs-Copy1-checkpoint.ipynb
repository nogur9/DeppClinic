{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "556360a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"../../utils\")\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, precision_recall_curve, roc_curve, auc\n",
    "\n",
    "from questionnaires_aggregation import c_ssrs_aggregation\n",
    "from utils import impute_from_column, simple_eda\n",
    "from questions_columns import c_ssrs, sci_af_ca\n",
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f291d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train, validation, and test sets\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "c_ssrs = c_ssrs[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf717d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_for_research.csv\")\n",
    "df_intake = df[df.measurement == 'time1']\n",
    "df_target = df[df.measurement == 'time2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebe27a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nogur\\Documents\\DeppClinic\\research\\Prediction_suicidal_behivior_one_month\\../../utils\\utils.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[impute_to] = np.where(df[impute_to].isnull(), df[impute_from], df[impute_to])\n",
      "C:\\Users\\nogur\\anaconda3\\envs\\DeppClinic\\lib\\site-packages\\pandas\\core\\indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "df_target = impute_from_column(df_target, impute_to = 'c_ssrs_6', impute_from = 'c_ssrs_last_visit_6')\n",
    "df_target.loc[df_target.query('c_ssrs_1 == 0 & c_ssrs_2 == 0').index, c_ssrs] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac08df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df_target.dropna(subset=c_ssrs, thresh=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce988de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target['c_ssrs_stb'] = c_ssrs_aggregation(df_target, severity = 'stb')\n",
    "df_target = df_target[['c_ssrs_stb', 'id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebec6fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42993b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 258)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69a07c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intake = df_intake.dropna(subset=sci_af_ca, thresh=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdd30967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237, 41)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intake = df_intake[sci_af_ca + ['id']]\n",
    "df_intake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d96d086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_intake['id'].isin(df_target['id']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c37d2a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_prediction = pd.merge(df_intake, df_target, on='id', how='inner')\n",
    "data_for_prediction['label'] = (data_for_prediction['c_ssrs_stb'] > 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cb54e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_af_agg = {'Factor1': ['sci_af_ca_5',\n",
    "  'sci_af_ca_6',\n",
    "  'sci_af_ca_13',\n",
    "  'sci_af_ca_15',\n",
    "  'sci_af_ca_16',\n",
    "  'sci_af_ca_19',\n",
    "  'sci_af_ca_20',\n",
    "  'sci_af_ca_22',\n",
    "  'sci_af_ca_24',\n",
    "  'sci_af_ca_25'],\n",
    " 'Factor2': ['sci_af_ca_1',\n",
    "  'sci_af_ca_2',\n",
    "  'sci_af_ca_3',\n",
    "  'sci_af_ca_7',\n",
    "  'sci_af_ca_8',\n",
    "  'sci_af_ca_9',\n",
    "  'sci_af_ca_10',\n",
    "  'sci_af_ca_11',\n",
    "  'sci_af_ca_14',\n",
    "  'sci_af_ca_17',\n",
    "  'sci_af_ca_26'],\n",
    " 'Factor3': ['sci_af_ca_4',\n",
    "  'sci_af_ca_12',\n",
    "  'sci_af_ca_18',\n",
    "  'sci_af_ca_21',\n",
    "  'sci_af_ca_23',\n",
    "  'sci_af_ca_27',\n",
    "  'sci_af_ca_28'],\n",
    " 'Factor4': ['sci_af_ca_29',\n",
    "  'sci_af_ca_30',\n",
    "  'sci_af_ca_31',\n",
    "  'sci_af_ca_32',\n",
    "  'sci_af_ca_33',\n",
    "  'sci_af_ca_34',\n",
    "  'sci_af_ca_40'],\n",
    " 'Factor5': ['sci_af_ca_35',\n",
    "  'sci_af_ca_36',\n",
    "  'sci_af_ca_37',\n",
    "  'sci_af_ca_38',\n",
    "  'sci_af_ca_39']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e30f434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sci_af_agg.keys():\n",
    "    data_for_prediction[key] = data_for_prediction[sci_af_agg[key]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3424dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e95d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de028bb635c94996b6603944ee949ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f681efa034849128c8f62a2c4daf905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_for_prediction = pd.merge(df_intake, df_target, on='id', how='inner')\n",
    "data_for_prediction['label'] = (data_for_prediction['c_ssrs_stb'] > 3).astype(int)\n",
    "if True:\n",
    "    simple_eda(data_for_prediction, columns = list(data_for_prediction.columns), title = 'all', display_additional_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0be634d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_for_prediction[sci_af_ca+ list(sci_af_agg.keys())]\n",
    "label = data_for_prediction['c_ssrs_stb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "980bebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=test_ratio, random_state=42, stratify=label)\n",
    "\n",
    "# Splitting the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_ratio/(train_ratio+val_ratio), random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee1470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2741dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CatBoostClassifier object with early stopping based on the validation set\n",
    "eval_set  = [(X_val, y_val)]\n",
    "model = CatBoostRegressor(random_state=42)\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X_train, y_train, eval_set=eval_set, early_stopping_rounds = 5)#, eval_set=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model on the training and validation sets\n",
    "\n",
    "# Make predictions on the training and validation sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "#y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "y_val_pred = model.predict(X_val)\n",
    "#y_val_prob = model.predict_proba(X_val)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c807a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and print various performance metrics\n",
    "def print_performance_metrics(y_true, y_pred, y_prob):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "#     precision_recall_auc = auc(*precision_recall_curve(y_true, y_prob)[:2])\n",
    "#     fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'ROC AUC: {roc_auc:.4f}')\n",
    "#     print(f'Precision-Recall AUC: {precision_recall_auc:.4f}')\n",
    "#     print(f'FPR: {fpr}')\n",
    "#     print(f'TPR: {tpr}')\n",
    "#     print(f'Thresholds: {_}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce9760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, max_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5415ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{max_error(y_val, y_val_pred) = }\\n{r2_score(y_val, y_val_pred) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b256d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{max_error(y_train, y_train_pred) = }\\n{r2_score(y_train, y_train_pred) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a3a3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620b5665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38262b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89     0\n",
       "102    0\n",
       "76     1\n",
       "40     1\n",
       "7      0\n",
       "      ..\n",
       "16     0\n",
       "94     1\n",
       "84     0\n",
       "115    0\n",
       "73     0\n",
       "Name: label, Length: 92, dtype: int32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49127967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d9d0302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy: 0.8152\n",
      "Precision: 0.5676\n",
      "Recall: 0.9545\n",
      "ROC AUC: 0.8961\n"
     ]
    }
   ],
   "source": [
    "# Print the performance metrics for the training set\n",
    "print('Training set performance:')\n",
    "#print_performance_metrics(y_train, y_train_pred, y_train_prob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7899d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set performance:\n",
      "Accuracy: 0.5161\n",
      "Precision: 0.2308\n",
      "Recall: 0.3750\n",
      "ROC AUC: 0.6413\n"
     ]
    }
   ],
   "source": [
    "# Print the performance metrics for the validation set\n",
    "print('Validation set performance:')\n",
    "print_performance_metrics(y_val, y_val_pred, y_val_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fa5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "accaa6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance scores:\n",
      "sci_af_ca_24: 23.6293\n",
      "sci_af_ca_21: 17.5072\n",
      "sci_af_ca_11: 13.7062\n",
      "sci_af_ca_20: 9.8723\n",
      "sci_af_ca_2: 9.4110\n",
      "sci_af_ca_38: 7.5143\n",
      "Factor4: 7.4314\n",
      "sci_af_ca_7: 5.6577\n",
      "sci_af_ca_3: 3.1631\n",
      "Factor5: 1.9622\n",
      "sci_af_ca_5: 0.1451\n",
      "sci_af_ca_1: 0.0000\n",
      "sci_af_ca_4: 0.0000\n",
      "sci_af_ca_6: 0.0000\n",
      "sci_af_ca_8: 0.0000\n",
      "sci_af_ca_9: 0.0000\n",
      "sci_af_ca_10: 0.0000\n",
      "sci_af_ca_12: 0.0000\n",
      "sci_af_ca_13: 0.0000\n",
      "sci_af_ca_14: 0.0000\n",
      "sci_af_ca_15: 0.0000\n",
      "sci_af_ca_16: 0.0000\n",
      "sci_af_ca_17: 0.0000\n",
      "sci_af_ca_18: 0.0000\n",
      "sci_af_ca_19: 0.0000\n",
      "sci_af_ca_22: 0.0000\n",
      "sci_af_ca_23: 0.0000\n",
      "sci_af_ca_25: 0.0000\n",
      "sci_af_ca_26: 0.0000\n",
      "sci_af_ca_27: 0.0000\n",
      "sci_af_ca_28: 0.0000\n",
      "sci_af_ca_29: 0.0000\n",
      "sci_af_ca_30: 0.0000\n",
      "sci_af_ca_31: 0.0000\n",
      "sci_af_ca_32: 0.0000\n",
      "sci_af_ca_33: 0.0000\n",
      "sci_af_ca_34: 0.0000\n",
      "sci_af_ca_35: 0.0000\n",
      "sci_af_ca_36: 0.0000\n",
      "sci_af_ca_37: 0.0000\n",
      "sci_af_ca_39: 0.0000\n",
      "sci_af_ca_40: 0.0000\n",
      "Factor1: 0.0000\n",
      "Factor2: 0.0000\n",
      "Factor3: 0.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get feature importance scores\n",
    "feature_importance = model.get_feature_importance()\n",
    "feature_names = X_train.columns.tolist()\n",
    "# Print feature importance scores\n",
    "print('Feature importance scores:')\n",
    "for feature_name, score in sorted(zip(feature_names, feature_importance), reverse=1, key = lambda x: x[1]):\n",
    "    print(f'{feature_name}: {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993b27d8",
   "metadata": {},
   "source": [
    "cool, \n",
    "use the train-validation-test variables that you created in the last snippet, \n",
    "and train CatBoostClassifier, with early_stopping parameter based on the validation set.\n",
    "\n",
    "after that look at the performance scores on the training & validation sets.\n",
    "and the feature-importance scores\n",
    "\n",
    "Since it's a complicated task, we need to use the following metrics: accuracy, precision, recall, precision-recall-auc, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979fe7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeppClinic",
   "language": "python",
   "name": "deppclinic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
