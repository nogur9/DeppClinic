{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "556360a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"../../utils\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import missingno as msno\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, average_precision_score, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from questionnaires_aggregation import c_ssrs_aggregation, sci_af_ac_aggregation\n",
    "from utils import impute_from_column, simple_eda\n",
    "from questions_columns import sci_af_ca, suicidal_behavior\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import r2_score, max_error\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f291d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train, validation, and test sets\n",
    "train_ratio = 0.5\n",
    "val_ratio = 0.3\n",
    "test_ratio = 0.2\n",
    "missing_sci_af_ca = [f'sci_af_ca_{i}' for i in range(26,41)]\n",
    "suicidal_behavior.remove('chameleon_ideation_stu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcf717d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"../create_dataset/data_for_prediction_research.csv\")\n",
    "#df = df[df.age_child_pre > 11]\n",
    "df_intake = df[df.measurement == 'time1']\n",
    "df_target = df[df.measurement == 'time2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d77850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# data in the original df = 419\n",
      "\n",
      "# data in the df_target = 329\n",
      "# data in the df_intake = 408\n",
      "# data in the merged_times = 318\n",
      "\n",
      "# data in the df_target after removing missing data = 302\n",
      "# data in the df_intake after removing missing data = 237\n",
      "# data in the merged_times after removing missing data = 174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"# data in the original df = {df['id'].nunique()}\\n\")\n",
    "print(f\"# data in the df_target = {df_target['id'].nunique()}\")\n",
    "print(f\"# data in the df_intake = {df_intake['id'].nunique()}\")\n",
    "\n",
    "merged_times = pd.merge(df_intake, df_target, on='id', how='inner')\n",
    "print(f\"# data in the merged_times = {merged_times['id'].nunique()}\\n\")\n",
    "\n",
    "target_dropna = df_target.dropna(subset = suicidal_behavior, how='all')\n",
    "print(f\"# data in the df_target after removing missing data = {target_dropna['id'].nunique()}\")\n",
    "\n",
    "intake_dropna = df_intake.dropna(subset = sci_af_ca, thresh=20)\n",
    "print(f\"# data in the df_intake after removing missing data = {intake_dropna['id'].nunique()}\")\n",
    "\n",
    "merged_times_dropna = pd.merge(intake_dropna, target_dropna, on='id', how='inner')\n",
    "print(f\"# data in the merged_times after removing missing data = {merged_times_dropna['id'].nunique()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b25cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac08df06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_for_prediction['id'].nunique() = 174\n"
     ]
    }
   ],
   "source": [
    "df_target = df_target.dropna(subset= suicidal_behavior, how='all')#df_target.dropna(subset=suicidal_behavior, how='all')\n",
    "df_target['label'] = (df_target[suicidal_behavior].sum(axis=1) > 0).astype(int)\n",
    "df_target = df_target[['label', 'id'] + suicidal_behavior]\n",
    "\n",
    "df_intake = df_intake.dropna(subset=sci_af_ca, thresh=20)\n",
    "df_intake, sci_af_ac_factors = sci_af_ac_aggregation(df_intake)\n",
    "df_intake['missing_sci_af_ca'] = df_intake[missing_sci_af_ca].isna().all(axis=1)\n",
    "df_intake = df_intake[sci_af_ca + sci_af_ac_factors + ['missing_sci_af_ca', 'id']]\n",
    "\n",
    "\n",
    "data_for_prediction = pd.merge(df_intake, df_target, on='id', how='inner')\n",
    "print(f\"{data_for_prediction['id'].nunique() = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd680942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69a07c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda = False\n",
    "if eda:\n",
    "    simple_eda(data_for_prediction, columns = list(data_for_prediction.columns), title = 'suicidal behivior prediction based on sci_af_ac', display_additional_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6e0772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0be634d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N features = (174, 46)\n",
      "label.count() = 174\n",
      "label.sum() = 34\n",
      "pos ratio  = 0.24285714285714285 \n"
     ]
    }
   ],
   "source": [
    "features = data_for_prediction[sci_af_ca + sci_af_ac_factors + ['missing_sci_af_ca']]\n",
    "feature_names = features.columns.tolist()\n",
    "\n",
    "label = data_for_prediction['label']\n",
    "print(f\"N features = {features.shape}\\n{label.count() = }\\n{label.sum() = }\")\n",
    "print(f\"pos ratio  = {label.sum()/(label.count() - label.sum()) } \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dde15afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Load the dataset with missing values\n",
    "# Create the IterativeImputer object and fit the imputation model\n",
    "imputer = IterativeImputer(max_iter=20)\n",
    "features = imputer.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "980bebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=test_ratio, random_state=42, stratify=label)\n",
    "\n",
    "# Splitting the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_ratio/(train_ratio+val_ratio), random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "521fad1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = CatBoostClassifier(random_state=42, depth = 6, l2_leaf_reg = 10, auto_class_weights = 'Balanced',\\n                           langevin = True, score_function = 'L2', model_size_reg = 1.0, boosting_type = 'Ordered',\\n                           eval_metric='Precision', approx_on_full_history = True, eta=0.005,\\n                          random_strength = 2, n_estimators=100)\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model = CatBoostClassifier(random_state=42, depth = 6, l2_leaf_reg = 10, auto_class_weights = 'Balanced',\n",
    "                           langevin = True, score_function = 'L2', model_size_reg = 1.0, boosting_type = 'Ordered',\n",
    "                           eval_metric='Precision', approx_on_full_history = True, eta=0.005,\n",
    "                          random_strength = 2, n_estimators=100)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2741dc3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nogur\\anaconda3\\envs\\DeppClinic\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "eval_set  = [(X_val, y_val)]\n",
    "# model = CatBoostClassifier(random_state=42, l2_leaf_reg = 9, auto_class_weights = 'Balanced',\n",
    "#                            model_size_reg = 1.0, eval_metric='Precision', random_strength = 3)\n",
    "\n",
    "# # Fit the model on the training set\n",
    "# model.fit(X_train, y_train, eval_set=eval_set, early_stopping_rounds=2)\n",
    "# model = XGBClassifier(random_state=42, reg_lambda=9, scale_pos_weight=4,\n",
    "#                       max_delta_step=1.0, eval_metric='aucpr')\n",
    "\n",
    "model = LogisticRegression(class_weight = {0:0.2, 1:1})\n",
    "model.fit(X_train, y_train)#, eval_set=eval_set, early_stopping_rounds=2)\n",
    "\n",
    "# Make predictions on the training and validation sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_prob = model.predict_proba(X_val)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "070a30c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and print various performance metrics\n",
    "\n",
    "def print_performance_metrics(y_true, y_pred, y_prob):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    average_precision = average_precision_score(y_true, y_prob)\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'ROC AUC: {roc_auc:.4f}')\n",
    "    print(f'PR AUC: {average_precision:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d9d0302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy: 0.8721\n",
      "Precision: 0.6250\n",
      "Recall: 0.8824\n",
      "ROC AUC: 0.9531\n",
      "PR AUC: 0.8592\n"
     ]
    }
   ],
   "source": [
    "# Print the performance metrics for the training set\n",
    "print('Training set performance:')\n",
    "print_performance_metrics(y_train, y_train_pred, y_train_prob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7899d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set performance:\n",
      "Accuracy: 0.6792\n",
      "Precision: 0.2941\n",
      "Recall: 0.5000\n",
      "ROC AUC: 0.6326\n",
      "PR AUC: 0.4331\n"
     ]
    }
   ],
   "source": [
    "# Print the performance metrics for the validation set\n",
    "print('Validation set performance:')\n",
    "print_performance_metrics(y_val, y_val_pred, y_val_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592fa5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accaa6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance scores:\n",
      "sci_af_ca_19: 0.5367\n",
      "sci_af_ca_10: 0.4538\n",
      "sci_af_ca_28: 0.4340\n",
      "sci_af_ca_7: 0.4135\n",
      "sci_af_ca_23: 0.3303\n",
      "sci_af_ca_14: 0.3264\n",
      "sci_af_ca_25: 0.3153\n",
      "sci_af_ca_37: 0.2899\n",
      "sci_af_ca_6: 0.2880\n",
      "sci_af_ca_17: 0.2686\n",
      "sci_af_ca_38: 0.2534\n",
      "sci_af_ca_39: 0.2469\n",
      "sci_af_ca_9: 0.2158\n",
      "sci_af_ca_30: 0.2059\n",
      "sci_af_ca_32: 0.2035\n",
      "sci_af_ca_34: 0.1412\n",
      "sci_af_ca_13: 0.1207\n",
      "sci_af_ca_Factor4: 0.0866\n",
      "sci_af_ca_24: 0.0808\n",
      "sci_af_ca_29: 0.0678\n",
      "sci_af_ca_12: 0.0522\n",
      "sci_af_ca_5: 0.0376\n",
      "sci_af_ca_33: 0.0276\n",
      "sci_af_ca_Factor2: 0.0205\n",
      "sci_af_ca_Factor3: 0.0138\n",
      "sci_af_ca_20: -0.0039\n",
      "sci_af_ca_Factor1: -0.0190\n",
      "sci_af_ca_40: -0.0496\n",
      "sci_af_ca_Factor5: -0.0560\n",
      "sci_af_ca_2: -0.0645\n",
      "sci_af_ca_8: -0.1077\n",
      "missing_sci_af_ca: -0.1155\n",
      "sci_af_ca_18: -0.1564\n",
      "sci_af_ca_22: -0.1648\n",
      "sci_af_ca_27: -0.1799\n",
      "sci_af_ca_1: -0.1807\n",
      "sci_af_ca_21: -0.1965\n",
      "sci_af_ca_26: -0.2360\n",
      "sci_af_ca_35: -0.2411\n",
      "sci_af_ca_4: -0.2699\n",
      "sci_af_ca_11: -0.3626\n",
      "sci_af_ca_15: -0.4366\n",
      "sci_af_ca_31: -0.5099\n",
      "sci_af_ca_36: -0.6051\n",
      "sci_af_ca_3: -0.7060\n",
      "sci_af_ca_16: -0.7927\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get feature importance scores\n",
    "feature_importance = model.coef_[0]\n",
    "# Print feature importance scores\n",
    "print('Feature importance scores:')\n",
    "for feature_name, score in sorted(zip(feature_names, feature_importance), reverse=1, key = lambda x: x[1]):\n",
    "    print(f'{feature_name}: {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993b27d8",
   "metadata": {},
   "source": [
    "cool, \n",
    "use the train-validation-test variables that you created in the last snippet, \n",
    "and train CatBoostClassifier, with early_stopping parameter based on the validation set.\n",
    "\n",
    "after that look at the performance scores on the training & validation sets.\n",
    "and the feature-importance scores\n",
    "\n",
    "Since it's a complicated task, we need to use the following metrics: accuracy, precision, recall, precision-recall-auc, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3235cf",
   "metadata": {},
   "source": [
    "#### Create a CatBoostClassifier object with early stopping based on the validation set\n",
    "eval_set  = [(X_val, y_val)]\n",
    "#model = CatBoostClassifier(random_state=42, depth = 5, l2_leaf_reg = 7, loss_function='CrossEntropy', eval_metric='AUC')\n",
    "model = CatBoostClassifier(random_state=42, depth = 2, l2_leaf_reg = 10, class_weights = [1, 8], eval_metric='Precision')\n",
    "\n",
    "##### Fit the model on the training set\n",
    "model.fit(X_train, y_train, eval_set=eval_set, early_stopping_rounds = 5)#, eval_set=(X_val, y_val))\n",
    "\n",
    "\n",
    "#### Make predictions on the training and validation sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_prob = model.predict_proba(X_val)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343d116c",
   "metadata": {},
   "source": [
    "eval_set  = [(X_val, y_val)]\n",
    "model = CatBoostClassifier(random_state=4212, depth = 6, l2_leaf_reg = 10, auto_class_weights = 'Balanced',\n",
    "                           langevin = True, score_function = 'L2', model_size_reg = 1.0, boosting_type = 'Ordered',\n",
    "                           eval_metric='CrossEntropy', od_pval = 10**-2, od_wait=5, approx_on_full_history = True,\n",
    "                          random_strength = 2, leaf_estimation_iterations=2)\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X_train, y_train, eval_set=eval_set)#, eval_set=(X_val, y_val))\n",
    "\n",
    "\n",
    "# Make predictions on the training and validation sets\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_prob = model.predict_proba(X_val)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52043d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeppClinic",
   "language": "python",
   "name": "deppclinic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
